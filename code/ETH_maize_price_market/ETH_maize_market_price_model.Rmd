---
title: "Ensemble Prediction of Market Maize Prices in Ethiopia"
author: "Sebastian Palmas"
date:  "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) 
```

# INTRODUCTION
Maize price estimates covering a continuous geographical area are difficult to collect: It costs a lot and takes time to collect the data. Using the price of maize at known locations and the value of spatial variables at these locations, we can create a model for predicting maize prices. Given the values of the spatial variables, the model will consequently predict the price of maize in other locations.

The price predicted here are deviations from de-trended prices obtained by dividing each month’s observations by that month’s mean value, and then scaling to normalize.



# SETUP

The setup for this script is `ETH_maize_market_price_setup.Rmd`. In this file I create the calibration and validation datasets.

## Packages
We use the "sp", "raster" and "rgdal" R packages for creating and manipulating spatial data in this exercise. They are all add-on packages that have to be installed from CRAN.
```{r, results = 'hide'}
rm(list=ls()) 
library(dplyr)
library(ggplot2)

source("../plot_fitness.R")
```

# I. LOADING DATASETS
```{r}
CSA <- read.csv("../../data/prices/CSA_maize_market_price_data.csv")
CSA$Month_code <- factor(CSA$Month_code)
```


## Calibration and validation datasets
CSA data spans from July/2013 to May/2019. The calibration data will be all data until May 2018 and the validation dataset will be all that remains (i.e. the last year).


```{r}
# Training/Test set partition ---------------------------------------------
c.data <- CSA[CSA$Year %in% c(2013:2017) | (CSA$Year == 2018 & CSA$Month_code %in% c(1:5)), ]
v.data <- CSA[CSA$Year == 2019 | (CSA$Year == 2018 & CSA$Month_code %in% c(6:12)), ]
```

# II. FITTING INDIVIDUAL MODELS

We will use an ensemble method to predict the market maize prices. The models in the ensemble method are

* Stochastic Gradient boosting: from xgboost package
* Neural network
* PLS regression
* Random forest: from ranger package
* Regularized regression

These are the packages needed for all the models:
```{r, message = FALSE}
library(caret)
library(deepnet)
library(gbm)
library(glmnet)
library(pls)
library(randomForest)
```

This will be the list of covariates in the models
```{r}
covariates <- c("maize_Unmilled_norm_t0",
                "Month_code", "Longitude", "Latitude",
                "BIO1", "BIO12", "BIO15", "BIO7",
                "CEC",
                "DCELL", "DOR1", "DOR2", "DOWS", "DPOP1", "DPOP2",
                "EVI",
                #"LCS", "LCT", "LCU", 
                #"LSTD", "LSTN",
                #"MB1", "MB2", "MB3", "MB7", 
                "MDEM",
                #"NPPA", "NPPS",
                "PARA", "PARV",
                "PH", 
                #"S1VV", "S2B11", "S2B12", 
                "SLOPE", "SND", "SOC", "TIM", "WPOP",
                "rainfall_season")

```


## A) Stochastic gradient Boosting
```{r}
# Control setup
set.seed(1234)
tc <- trainControl(method = "cv",
                   number=10)   #10-fold Cross Validation

#Traning model
model.gbm <- train(x = c.data[,covariates], y = c.data[,1], 
                   method = "gbm", 
                   preProc = c("center", "scale"),
                   trControl = tc,
                   tuneGrid = expand.grid(.n.trees=seq(50,500,by=50), 
                                          .interaction.depth = 3,
                                          .shrinkage = 0.1,
                                          .n.minobsinnode = 100))

print(model.gbm)
```

```{r, echo=FALSE}
gbm.rsq <- rsq(obs = c.data[,1], pred = predict(model.gbm))
v.imp.gbm <- varImp(model.gbm)
plot(v.imp.gbm, top=28)
```

## B) Neural network
```{r, message=FALSE, warning=FALSE, eval=FALSE}
set.seed(1234)
tc <- trainControl(method = "cv", 
                   number = 10)   #10-fold Cross Validation

#Traning model
model.nn <- train(c.data[,covariates], c.data[,1], 
                  method = "dnn", 
                  preProc = c("center", "scale"), 
                  trControl = tc,
                  tuneGrid = expand.grid(layer1 = 2:6,
                                         layer2 = 0:3,
                                         layer3 = 0:3,
                                         hidden_dropout = 0,
                                         visible_dropout = 0))

print(model.nn)
```


```{r, echo=FALSE, eval=FALSE}
v.imp.nn <- varImp(model.nn)
plot(v.imp.nn, top=28)
```

## C) PLS Regression
```{r}
set.seed(1234)
tc <- trainControl(method = "cv", 
                   number = 10)   #10-fold Cross Validation

#Traning model
model.pls <- train(c.data[,covariates], c.data[,1], 
                   method = "pls", 
                   preProc = c("center", "scale"),
                   tuneGrid = expand.grid(ncomp = 1:10),
                   trControl = tc)

print(model.pls)

```

```{r, echo=FALSE}
pls.rsq <- rsq(obs = c.data[,1], pred = predict(model.pls))
v.imp.pls <- varImp(model.pls)
plot(v.imp.pls, top=28)
```

## D) Random Forest
### Tune The Forest
By "tune the forest", we mean the process of determining the optimal number of variables to consider at each split in a decision-tree. Too many prediction variables and the algorithm will over-fit; too few prediction variables and the algorithm will under-fit. so first, we use `tuneRF` function to get the possible optimal numbers of prediction variables. The `tuneRF` function takes two arguments: the prediction variables and the response variable.

```{r}
# Control setup
set.seed(1234)
tc <- trainControl(method = "oob")  #out of bag error for random forests

#Traning model
model.rf <- train(c.data[,covariates], c.data[,1], 
                  method = "rf",
                  preProc = c("center", "scale"),
                  trControl = tc)

print(model.rf)
```

```{r, echo=FALSE}
rf.rsq <- rsq(obs = c.data[,1], pred = predict(model.rf))
v.imp.rf <- varImp(model.rf, useModel = FALSE)
plot(v.imp.rf, top=28)
```
## D) Regional mean model
I'll compare all models to a national average and regional average.
```{r}
#average models
nat.avg <- c.data %>% group_by(Month_code) %>% 
  summarise(maize_Unmilled_norm_nat.avg = mean(maize_Unmilled_norm))

reg.avg <- c.data %>% group_by(Region,Month_code) %>% 
  summarise(maize_Unmilled_norm_reg.avg = mean(maize_Unmilled_norm))


#comparing avg models to measured
c.data.withavg <- left_join(c.data, nat.avg, by=c("Month_code")) %>% left_join(reg.avg, by=c("Region", "Month_code"))
```

## E) Linear Regression model
I'll compare all models to a linear regression that only includes month dummies, pop density, distance from Addis, latitude and longitude? 
```{r}
#average models
lm1 <- lm(maize_Unmilled_norm ~ Month_code + WPOP + DPOP1 + Longitude + Latitude, data = c.data)

summary(lm1)
```

```{r}
v.imp.gbm$importanceset

v.imp.gbm$importance$variable <- rownames(v.imp.gbm$importance)
v.imp.pls$importance$variable <- rownames(v.imp.pls$importance)
v.imp.rf$importance$variable <- rownames(v.imp.rf$importance)

varimp_table <- v.imp.gbm$importance %>% 
  left_join(v.imp.pls$importance, by = 'variable') %>% 
  left_join(v.imp.rf$importance, by = 'variable') %>% 
  rename(GBM = Overall.x,
         PLS = Overall.y,
         RF = Overall) %>% 
  dplyr::select(variable, GBM, PLS, RF)

write.table(x = varimp_table, file = "../../output/crop_market_price/models_var_importance.csv", sep = ",", row.names = FALSE)
```


# III. ENSEMBLE METHOD
The ensemble fitting will be done as a weighted average model using the estimated r squared from the calibration model 
```{r, echo=FALSE}
print(paste0("gbm.rsq: ", gbm.rsq))
print(paste0("pls.rsq: ", pls.rsq))
print(paste0("rf.rsq: ", rf.rsq))
```

```{r}
model.ens <- function(pred.gbm, pred.pls, pred.rf){
  gbm.rsq <- 0.766998139105605
  pls.rsq <- 0.689119845264237
  rf.rsq <- 0.707846789255578
  return((pred.gbm * gbm.rsq + pred.pls * pls.rsq + pred.rf * rf.rsq)/(gbm.rsq + pls.rsq + rf.rsq))
}

c.maize_Unmilled_norm.ens <- model.ens(predict(model.gbm), predict(model.pls), predict(model.rf))
```


```{r, echo=FALSE, fig.height=8}
par(mfrow=c(4,2))
plot_fitness(obs = c.data.withavg$maize_Unmilled_norm, pred = c.data.withavg$maize_Unmilled_norm_nat.avg, name = "Cal: National monthly avg.")
plot_fitness(obs = c.data.withavg$maize_Unmilled_norm, pred = c.data.withavg$maize_Unmilled_norm_reg.avg, name = "Cal: Regional monthly avg.")
plot_fitness(obs = c.data$maize_Unmilled_norm, pred = predict(lm1), name = "Cal: LM")
plot_fitness(obs = c.data$maize_Unmilled_norm, pred = predict(model.gbm), name = "Cal: GBM")
plot_fitness(obs = c.data$maize_Unmilled_norm, pred = predict(model.pls), name = "Cal: PLS")
plot_fitness(obs = c.data$maize_Unmilled_norm, pred = predict(model.rf), name = "Cal: RF")
plot_fitness(obs = c.data$maize_Unmilled_norm, pred = c.maize_Unmilled_norm.ens, name = "Cal: Ensemble")
```


# IV. MODEL VALIDATION

We will use the validation dataset (LSMS) to check the prediction.

## IV.I Prediction on validation dataset
```{r}
#Getting predictions on the validation datasets
#Average models
v.data.withavg <- left_join(v.data, nat.avg, by=c("Month_code")) %>% left_join(reg.avg, by=c("Region", "Month_code"))

#ML models
v.maize_Unmilled_norm.gbm <- predict(model.gbm, newdata = v.data)
#maip_USDkg.nn <- predict(model.nn, newdata = v.data)
v.maize_Unmilled_norm.pls <- predict(model.pls, newdata = v.data)
v.maize_Unmilled_norm.rf <- predict(model.rf, newdata = v.data)

#Putting together ensemble results to a table
v.maize_Unmilled_norm.ens <- model.ens(v.maize_Unmilled_norm.gbm, v.maize_Unmilled_norm.pls, v.maize_Unmilled_norm.rf)
```

```{r, echo=FALSE, fig.height=8}
par(mfrow=c(4,2))
plot_fitness(obs = v.data.withavg[,1], pred = v.data.withavg$maize_Unmilled_norm_nat.avg, name = "Val: National monthly avg.")
plot_fitness(obs = v.data.withavg[,1], pred = v.data.withavg$maize_Unmilled_norm_reg.avg, name = "Val: Regional monthly avg.")
plot_fitness(obs = v.data$maize_Unmilled_norm, pred = predict(lm1, newdata=v.data), name = "Val: LM")
plot_fitness(obs = v.data$maize_Unmilled_norm, pred = v.maize_Unmilled_norm.gbm, name = "Val: GBM")
plot_fitness(obs = v.data$maize_Unmilled_norm, pred = v.maize_Unmilled_norm.pls, name = "Val: PLS")
plot_fitness(obs = v.data$maize_Unmilled_norm, pred = v.maize_Unmilled_norm.rf, name = "Val: RF")
plot_fitness(obs = v.data$maize_Unmilled_norm, pred = v.maize_Unmilled_norm.ens, name = "Val: Ensemble")
```
## IV.II Prediction on LSMS
```{r}
LSMS <- read.csv("../../data/prices/LSMS_maize_market_price.csv")

#Changing Month_code to a factor
LSMS$Month_code <- factor(LSMS$Month_code, levels=c(1:12))

#ML models
v2.maize_Unmilled_norm.gbm <- predict(model.gbm, newdata = LSMS)
#maize_Unmilled_norm.nn <- predict(model.nn, newdata = LSMS)
v2.maize_Unmilled_norm.pls <- predict(model.pls, newdata = LSMS)
v2.maize_Unmilled_norm.rf <- predict(model.rf, newdata = LSMS)

#Putting together ensemble results to a table
v2.maize_Unmilled_norm.ens <- model.ens(v2.maize_Unmilled_norm.gbm, v2.maize_Unmilled_norm.pls, v2.maize_Unmilled_norm.rf)

```

```{r, echo=FALSE, fig.height=8}
par(mfrow=c(3,2))
plot_fitness(obs = LSMS$maize_Unmilled_norm, pred = predict(lm1, newdata=LSMS), name = "LSMS Val: LR")
plot_fitness(obs = LSMS$maize_Unmilled_norm, pred = v2.maize_Unmilled_norm.gbm, name = "LSMS Val: GBM")
plot_fitness(obs = LSMS$maize_Unmilled_norm, pred = v2.maize_Unmilled_norm.pls, name = "LSMS Val: PLS")
plot_fitness(obs = LSMS$maize_Unmilled_norm, pred = v2.maize_Unmilled_norm.rf, name = "LSMSVal: RF")
plot_fitness(obs = LSMS$maize_Unmilled_norm, pred = v2.maize_Unmilled_norm.ens, name = "LSMSVal: Ensemble")
```

# V. TABLES AND PLOTS FOR MANUSCRIPT
## V.1 TABLE OF RMSE AND R2 FOR PAPER 

```{r, echo=FALSE}
rmse_table <- as_tibble(matrix(nrow=4, ncol = 6))
colnames(rmse_table) <- c("model", "RMSE-Cal", "r2-Cal", "RMSE-Val", "r2-Val", "RMSE-Val2", "r2-Val2")
rmse_table$model <- c("PLS", "GBM", "RF", "ENS")


rmse_table$`RMSE-Cal` <- c(RMSE(c.data$maize_Unmilled_norm, predict(model.gbm)) %>% round(digits=3),
                           RMSE(c.data$maize_Unmilled_norm, predict(model.pls)) %>% round(digits=3),
                           RMSE(c.data$maize_Unmilled_norm, predict(model.rf)) %>% round(digits=3),
                           RMSE(c.data$maize_Unmilled_norm, c.maize_Unmilled_norm.ens) %>% round(digits=3))

rmse_table$`RMSE-Val` <- c(RMSE(v.data$maize_Unmilled_norm, pred = v.maize_Unmilled_norm.gbm) %>% round(digits=3),
                           RMSE(v.data$maize_Unmilled_norm, pred = v.maize_Unmilled_norm.pls) %>% round(digits=3),
                           RMSE(v.data$maize_Unmilled_norm, pred = v.maize_Unmilled_norm.rf) %>% round(digits=3),
                           RMSE(v.data$maize_Unmilled_norm, pred = v.maize_Unmilled_norm.ens) %>% round(digits=3))

rmse_table$`RMSE-Val2` <- c(RMSE(LSMS$maize_Unmilled_norm, pred = v2.maize_Unmilled_norm.gbm) %>% round(digits=3),
                            RMSE(LSMS$maize_Unmilled_norm, pred = v2.maize_Unmilled_norm.pls) %>% round(digits=3),
                            RMSE(LSMS$maize_Unmilled_norm, pred = v2.maize_Unmilled_norm.rf) %>% round(digits=3),
                            RMSE(LSMS$maize_Unmilled_norm, pred = v2.maize_Unmilled_norm.ens) %>% round(digits=3))

rmse_table$`r2-Cal` <- c(rsq(c.data$maize_Unmilled_norm, predict(model.gbm)) %>% round(digits=3),
                         rsq(c.data$maize_Unmilled_norm, predict(model.pls)) %>% round(digits=3),
                         rsq(c.data$maize_Unmilled_norm, predict(model.rf)) %>% round(digits=3),
                         rsq(c.data$maize_Unmilled_norm, c.maize_Unmilled_norm.ens) %>% round(digits=3))

rmse_table$`r2-Val` <- c(rsq(v.data$maize_Unmilled_norm, pred = v.maize_Unmilled_norm.gbm) %>% round(digits=3),
                         rsq(v.data$maize_Unmilled_norm, pred = v.maize_Unmilled_norm.pls) %>% round(digits=3),
                         rsq(v.data$maize_Unmilled_norm, pred = v.maize_Unmilled_norm.rf) %>% round(digits=3),
                         rsq(v.data$maize_Unmilled_norm, pred = v.maize_Unmilled_norm.ens) %>% round(digits=3))

rmse_table$`r2-Val2` <- c(rsq(LSMS$maize_Unmilled_norm, pred = v2.maize_Unmilled_norm.gbm) %>% round(digits=3),
                          rsq(LSMS$maize_Unmilled_norm, pred = v2.maize_Unmilled_norm.pls) %>% round(digits=3),
                          rsq(LSMS$maize_Unmilled_norm, pred = v2.maize_Unmilled_norm.rf) %>% round(digits=3),
                          rsq(LSMS$maize_Unmilled_norm, pred = v2.maize_Unmilled_norm.ens) %>% round(digits=3))

write.table(x = rmse_table, file = "../../output/crop_market_price/models_RMSE_r2.csv", sep = ",", row.names = FALSE)
print(rmse_table)
```

## V.2 SCATTERPLOTS

```{r, echo=FALSE}
library(ggpubr)
 

g.gbm <- ggplot() + 
  geom_point(aes(x = c.data$maize_Unmilled_norm, y = predict(model.gbm)), alpha = 0.3) +
  theme_classic() + 
  xlim(-4, 4) + ylim(-4, 4) +
  ggtitle("GBM") + xlab("Observed maize price") + ylab("Predicted maize price") +
  annotate('text', x = -2.5, y = 4, label = paste0("RMSE==", rmse_table$`RMSE-Cal`[1]), parse = TRUE, size=3)  +
  annotate('text', x = -2.5, y = 2.5, label = paste0("R^{2}==", rmse_table$`r2-Cal`[1]), parse = TRUE, size=3)  +
  geom_abline(slope = 1, intercept = 0)

g.pls <- ggplot() + 
  geom_point(aes(x = c.data$maize_Unmilled_norm, y = predict(model.pls)), alpha = 0.3) +
  theme_classic() + 
  xlim(-4, 4) + ylim(-4, 4) +
  ggtitle("PLS") + xlab("Observed maize price") + ylab("Predicted maize price") +
  annotate('text', x = -2.5, y = 4, label = paste0("RMSE==", rmse_table$`RMSE-Cal`[2]), parse = TRUE, size=3)  +
  annotate('text', x = -2.5, y = 2.5, label = paste0("R^{2}==", rmse_table$`r2-Cal`[2]), parse = TRUE, size=3)  +
  geom_abline(slope = 1, intercept = 0)

g.rf <- ggplot() + 
  geom_point(aes(x = c.data$maize_Unmilled_norm, y = predict(model.rf)), alpha = 0.3) +
  theme_classic() + 
  xlim(-4, 4) + ylim(-4, 4) +
  ggtitle("RF") + xlab("Observed maize price") + ylab("Predicted maize price") +
  annotate('text', x = -2.5, y = 4, label = paste0("RMSE==", rmse_table$`RMSE-Cal`[3]), parse = TRUE, size=3)  +
  annotate('text', x = -2.5, y = 2.5, label = paste0("R^{2}==", rmse_table$`r2-Cal`[3]), parse = TRUE, size=3)  +
 geom_abline(slope = 1, intercept = 0)

g.ens <- ggplot() + 
  geom_point(aes(x = c.data$maize_Unmilled_norm, y = c.maize_Unmilled_norm.ens), stroke=0, alpha = 0.3) +
  theme_classic() + 
  xlim(-4, 4) + ylim(-4, 4) +
  ggtitle("Ensemble") + xlab("Observed maize price") + ylab("Predicted maize price") +
  annotate('text', x = -2.5, y = 4, label = paste0("RMSE==", rmse_table$`RMSE-Cal`[4]), parse = TRUE, size=3)  +
  annotate('text', x = -2.5, y = 2.5, label = paste0("R^{2}==", rmse_table$`r2-Cal`[4]), parse = TRUE, size=3)  +
  geom_abline(slope = 1, intercept = 0)


g <- ggarrange(g.gbm, g.pls, g.rf, g.ens, ncol=2, nrow =2)
g
ggexport(g, filename = "../../output/plots/scatterplot_cal.tiff",
         width = 400, height = 400)
```


```{r}
g.gbm <- ggplot() + 
  geom_point(aes(x = v.data$maize_Unmilled_norm, y = v.maize_Unmilled_norm.gbm), alpha = 0.3) +
  theme_classic() + 
  xlim(-4, 4) + ylim(-4, 4) +
  ggtitle("GBM") + xlab("Observed maize price") + ylab("Predicted maize price") +
  annotate('text', x = -2.5, y = 4, label = paste0("RMSE==", rmse_table$`RMSE-Val`[1]), parse = TRUE, size=3)  +
  annotate('text', x = -2.5, y = 2.5, label = paste0("R^{2}==", rmse_table$`r2-Val`[1]), parse = TRUE, size=3)  +
  geom_abline(slope = 1, intercept = 0)

g.pls <- ggplot() + 
  geom_point(aes(x = v.data$maize_Unmilled_norm, y = v.maize_Unmilled_norm.pls), alpha = 0.3) +
  theme_classic() + 
  xlim(-4, 4) + ylim(-4, 4) +
  ggtitle("PLS") + xlab("Observed maize price") + ylab("Predicted maize price") +
  annotate('text', x = -2.5, y = 4, label = paste0("RMSE==", rmse_table$`RMSE-Val`[2]), parse = TRUE, size=3)  +
  annotate('text', x = -2.5, y = 2.5, label = paste0("R^{2}==", rmse_table$`r2-Val`[2]), parse = TRUE, size=3)  +
  geom_abline(slope = 1, intercept = 0)

g.rf <- ggplot() + 
  geom_point(aes(x = v.data$maize_Unmilled_norm, y = v.maize_Unmilled_norm.rf), alpha = 0.3) +
  theme_classic() + 
  xlim(-4, 4) + ylim(-4, 4) +
  ggtitle("RF") + xlab("Observed maize price") + ylab("Predicted maize price") +
  annotate('text', x = -2.5, y = 4, label = paste0("RMSE==", rmse_table$`RMSE-Val`[3]), parse = TRUE, size=3)  +
  annotate('text', x = -2.5, y = 2.5, label = paste0("R^{2}==", rmse_table$`r2-Val`[3]), parse = TRUE, size=3)  +
  geom_abline(slope = 1, intercept = 0)

g.ens <- ggplot() + 
  geom_point(aes(x = v.data$maize_Unmilled_norm, y = v.maize_Unmilled_norm.ens), alpha = 0.3) +
  theme_classic() + 
  xlim(-4, 4) + ylim(-4, 4) +
  ggtitle("Ensemble") + xlab("Observed maize price") + ylab("Predicted maize price") +
  annotate('text', x = -2.5, y = 4, label = paste0("RMSE==", rmse_table$`RMSE-Val`[4]), parse = TRUE, size=3)  +
  annotate('text', x = -2.5, y = 2.5, label = paste0("R^{2}==", rmse_table$`r2-Val`[4]), parse = TRUE, size=3)  +
  geom_abline(slope = 1, intercept = 0)


g <- ggarrange(g.gbm, g.pls, g.rf, g.ens, ncol=2, nrow =2)
g

ggexport(g, filename = "../../output/plots/scatterplot_val1.tiff",
         width = 500, height = 500)
```



```{r}
g.gbm <- ggplot() + 
  geom_point(aes(x = LSMS$maize_Unmilled_norm, y = v2.maize_Unmilled_norm.gbm), alpha = 0.3) +
  theme_classic() + 
  xlim(-4, 4) + ylim(-4, 4) +
  ggtitle("GBM") + xlab("Observed maize price") + ylab("Predicted maize price") +
  annotate('text', x = -2.5, y = 4, label = paste0("RMSE==", rmse_table$`RMSE-Val2`[1]), parse = TRUE, size=3)  +
  annotate('text', x = -2.5, y = 2.5, label = paste0("R^{2}==", rmse_table$`r2-Val2`[1]), parse = TRUE, size=3)  +
  geom_abline(slope = 1, intercept = 0)

g.pls <- ggplot() + 
  geom_point(aes(x = LSMS$maize_Unmilled_norm, y = v2.maize_Unmilled_norm.pls), alpha = 0.3) +
  theme_classic() + 
  xlim(-4, 4) + ylim(-4, 4) +
  ggtitle("PLS") + xlab("Observed maize price") + ylab("Predicted maize price") +
  annotate('text', x = -2.5, y = 4, label = paste0("RMSE==", rmse_table$`RMSE-Val2`[2]), parse = TRUE, size=3)  +
  annotate('text', x = -2.5, y = 2.5, label = paste0("R^{2}==", rmse_table$`r2-Val2`[2]), parse = TRUE, size=3)  +
  geom_abline(slope = 1, intercept = 0)

g.rf <- ggplot() + 
  geom_point(aes(x = LSMS$maize_Unmilled_norm, y = v2.maize_Unmilled_norm.rf), alpha = 0.3) +
  theme_classic() + 
  xlim(-4, 4) + ylim(-4, 4) +
  ggtitle("RF") + xlab("Observed maize price") + ylab("Predicted maize price") +
  annotate('text', x = -2.5, y = 4, label = paste0("RMSE==", rmse_table$`RMSE-Val2`[3]), parse = TRUE, size=3)  +
  annotate('text', x = -2.5, y = 2.5, label = paste0("R^{2}==", rmse_table$`r2-Val2`[3]), parse = TRUE, size=3)  +
  geom_abline(slope = 1, intercept = 0)

g.ens <- ggplot() + 
  geom_point(aes(x = LSMS$maize_Unmilled_norm, y = v2.maize_Unmilled_norm.ens), alpha = 0.3) +
  theme_classic() + 
  xlim(-4, 4) + ylim(-4, 4) +
  ggtitle("Ensemble") + xlab("Observed maize price") + ylab("Predicted maize price") +
  annotate('text', x = -2.5, y = 4, label = paste0("RMSE==", rmse_table$`RMSE-Val2`[4]), parse = TRUE, size=3)  +
  annotate('text', x = -2.5, y = 2.5, label = paste0("R^{2}==", rmse_table$`r2-Val2`[4]), parse = TRUE, size=3)  +
  geom_abline(slope = 1, intercept = 0)


g <- ggarrange(g.gbm, g.pls, g.rf, g.ens, ncol=2, nrow =2)
g

ggexport(g, filename = "../../output/plots/scatterplot_val2.tiff",
         width = 500, height = 500)
```



# VI. EXPORTING MODELS TO USE IN RASTER PRICE PREDICTION
```{r}
save(model.gbm, file="../../output/models/maip_USDkg_gbm.rda")
save(model.pls, file="../../output/models/maip_USDkg_pls.rda")
save(model.rf, file="../../output/models/maip_USDkg_rf.rda")
save(model.ens, file="../../output/models/maip_USDkg_ens.rda")
```
